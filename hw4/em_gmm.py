# -*- coding: utf-8 -*-
"""em gmm

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1obBbFzfCD8VcLw6CAhV6gcgXunc5VqGp
"""

import numpy as np
import matplotlib.pyplot as plt

"""## Multivariate Gaussian function

$f(\mathbf{x}, \boldsymbol{\mu}, \Sigma) = (2\pi)^{-M/2}|\Sigma|^{-1/2}~e^{\frac{-1}{2}(\mathbf{x}-\boldsymbol{\mu})^T\Sigma^{-1}(\mathbf{x}-\boldsymbol{\mu})}$

"""


def gaussian(x, mu, cov):
    # x and mu should be vectors in numpy, shape=(2,)
    # cov should be a matrix in numpy, shape=(2,2)
    M = 2
    scale = (2 * np.pi) ** (-M / 2) * np.linalg.det(cov) ** (-1 / 2)
    return scale * np.exp(-(1 / 2) * (x - mu).T @ np.linalg.inv(cov) @ (x - mu))


"""## Plot Gaussian contours function"""


def plot_gaussian(mu, cov, x1_min=-10, x1_max=10, x2_min=-10, x2_max=10, color=None):
    x1_values = np.linspace(x1_min, x1_max, 101)
    x2_values = np.linspace(x2_min, x2_max, 101)

    x1_grid, x2_grid = np.meshgrid(x1_values, x2_values)

    M, N = x1_grid.shape
    y_grid = np.zeros((M, N))

    x = np.zeros((2,))

    for i in range(M):
        for j in range(N):
            x[0] = x1_grid[i, j]
            x[1] = x2_grid[i, j]

            y_grid[i, j] = gaussian(x, mu, cov)

    plt.contour(x1_grid, x2_grid, y_grid, colors=color)


"""## Load data
Note: The code assumes that the data file is in the same folder as the jupyter notebook. In Google colab, you can upload the file directly into the workspace by in the Files tab on the left.
"""

X = np.loadtxt("./gmm_data.csv", delimiter=",")
print(X.shape)

"""## Initial parameters"""

K = 4
mu_list = []
sigma_list = []
pi_list = []

for k in range(K):
    mu_list.append((k + 1) * np.ones((2,)))
    sigma_list.append(np.eye(2))
    pi_list.append(1 / K)

"""## Plot data with initial Gaussian contours"""

# Square figure size
plt.figure(figsize=(8, 8))

# Plot points
plt.plot(X[:, 0], X[:, 1], 'o', markerfacecolor="None", alpha=0.3)

# Plot K Gaussians
colors = ['tab:orange', 'tab:green', 'tab:red', 'tab:purple']
for k in range(K):
    plot_gaussian(mu_list[k], sigma_list[k], color=colors[k])

# Axes
plt.gca().axhline(y=0, color='gray')
plt.gca().axvline(x=0, color='gray')

# Labels
plt.xlabel("$x_1$", fontsize=20)
plt.ylabel("$x_2$", fontsize=20)
plt.title("Iteration 0", fontsize=20)


def e_step(X, pi_list, mu_list, sigma_list):
    num_data = len(X)
    ret = np.zeros((num_data, K))
    for i in range(num_data):
        for j in range(K):
            ret[i][j] = pi_list[j] * gaussian(X[i], mu_list[j], sigma_list[j])
    return ret / ret.sum(axis=1)[:, np.newaxis]


def EM_alg(data, init_means, init_covariances, init_weights, maxiter=1000, thresh=1e-4):
    means = init_means[:]
    covariances = init_covariances[:]
    weights = init_weights[:]
    num_data = len(data)
    num_dim = len(data[0])
    num_clusters = len(means)
    resp = np.zeros((num_data, num_clusters))
    ll = loglikelihood(data, weights, means, covariances)
    ll_trace = [ll]

    for it in range(maxiter):
        print("Iteration %s" % it)

        # pi
        resp = e_step(data, weights, means, covariances)
        counts = np.sum(resp, axis=0)
        num_clusters = len(counts)
        weights = [0.] * num_clusters
        for k in range(num_clusters):
            weights[k] = counts[k] / np.sum(counts)

        # mu
        num_clusters = len(counts)
        num_data = len(data)
        means = [np.zeros(len(data[0]))] * num_clusters
        for k in range(num_clusters):
            weighted_sum = 0.
            for i in range(num_data):
                weighted_sum += data[i] * resp[i][k]
            means[k] = weighted_sum / counts[k]

        # sigma
        num_clusters = len(counts)
        num_dim = len(data[0])
        num_data = len(data)
        covariances = [np.zeros((num_dim, num_dim))] * num_clusters
        for k in range(num_clusters):
            weighted_sum = np.zeros((num_dim, num_dim))
            for i in range(num_data):
                weighted_sum += resp[i][k] * np.outer(data[i] - means[k], data[i] - means[k])
            covariances[k] = weighted_sum / counts[k]

    out = {'weights': weights, 'means': means, 'covs': covariances, 'loglik': ll_trace, 'resp': resp}
    return out


results = EM_alg(X, mu_list, sigma_list, pi_list, maxiter=1)
# Square figure size
plt.figure(figsize=(8, 8))
plt.plot(X[:, 0], X[:, 1], 'o', markerfacecolor="None", alpha=0.3)
colors = ['tab:orange', 'tab:green', 'tab:red', 'tab:purple']
for i in range(K):
    plot_gaussian(results['means'][i], results['covs'][i])

# Axes
plt.gca().axhline(y=0, color='gray')
plt.gca().axvline(x=0, color='gray')

# Labels
plt.xlabel("$x_1$", fontsize=20)
plt.ylabel("$x_2$", fontsize=20)
plt.title("Iteration 100", fontsize=20)
